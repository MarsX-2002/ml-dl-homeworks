{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71fb840a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define device: use CUDA if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8ba6494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "url = \"https://raw.githubusercontent.com/karpathy/makemore/refs/heads/master/names.txt\"\n",
    "data = urllib.request.urlopen(url).read().decode(\"utf-8\").splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0efc8fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary\n",
    "chars = sorted(list(set(''.join(data))))\n",
    "chars = ['.'] + chars \n",
    "stoi = {ch: i for i, ch in enumerate(chars)}  # encoder\n",
    "itos = {i: ch for ch, i in stoi.items()}  # decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75d608fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: torch.Size([228146, 3])\n",
      "Y.shape: torch.Size([228146])\n",
      "\n",
      "X1 is tensor([0, 0, 5]) and Y1 is 13\n"
     ]
    }
   ],
   "source": [
    "# build dataset\n",
    "def build_dataset(names: list[str], context_len: int = 3) -> tuple[list[int], list[int]]:\n",
    "    X, Y = [], []\n",
    "    for name in names:\n",
    "        s = '.' * context_len + name + '.'  # ...emma.\n",
    "        for i in range(context_len, len(s)):\n",
    "            context = s[i - context_len:i]\n",
    "            target = s[i]\n",
    "            X.append([stoi[c] for c in context])\n",
    "            Y.append(stoi[target])\n",
    "    X = torch.tensor(X, dtype=torch.long)\n",
    "    Y = torch.tensor(Y, dtype=torch.long)\n",
    "    return X, Y\n",
    "\n",
    "X, Y = build_dataset(data, 3)\n",
    "print(f\"X.shape: {X.shape}\\nY.shape: {Y.shape}\")\n",
    "print(f\"\\nX1 is {X[1]} and Y1 is {Y[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c08083ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "# Move data to device\n",
    "X_train, Y_train = X_train.to(device), Y_train.to(device)\n",
    "X_test, Y_test = X_test.to(device), Y_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a125d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengioLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, context_size, hidden_size):\n",
    "        super(BengioLanguageModel, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.emb_dim = emb_dim\n",
    "        self.context_size = context_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.E = nn.Parameter(torch.randn(vocab_size, emb_dim) * 0.01)\n",
    "        self.Wx = nn.Parameter(torch.randn(hidden_size, context_size * emb_dim) * 0.5)\n",
    "        self.bh = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.Wy = nn.Parameter(torch.randn(vocab_size, hidden_size) * 0.5)\n",
    "        self.by = nn.Parameter(torch.zeros(vocab_size))\n",
    "\n",
    "    def forward(self, X):\n",
    "        emb = self.E[X] \n",
    "        emb_cat = emb.view(emb.size(0), -1)  # flatten context embeddings\n",
    "        h = torch.tanh(torch.matmul(emb_cat, self.Wx.t()) + self.bh)\n",
    "        logits = torch.matmul(h, self.Wy.t()) + self.by\n",
    "        return logits\n",
    "\n",
    "    def generate(self, start_context, itos, max_length=20):\n",
    "        self.eval()\n",
    "        context = start_context.copy()\n",
    "        out = []\n",
    "        with torch.no_grad():\n",
    "            for _ in range(max_length):\n",
    "                x = torch.tensor([context], dtype=torch.long, device=device)\n",
    "                logits = self.forward(x)\n",
    "                probs = F.softmax(logits, dim=1)\n",
    "                ix = torch.multinomial(probs, num_samples=1).item()\n",
    "                if ix == 0:  # end token\n",
    "                    break\n",
    "                out.append(ix)\n",
    "                context = context[1:] + [ix]\n",
    "        return ''.join(itos[i] for i in out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "224ca9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = BengioLanguageModel(vocab_size=len(stoi), emb_dim=20, context_size=3, hidden_size=100).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b845af78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train loss=3.3095 Test loss=3.0793\n",
      "Epoch 20: Train loss=2.6294 Test loss=2.6240\n",
      "Epoch 40: Train loss=2.5708 Test loss=2.5689\n",
      "Epoch 60: Train loss=2.5370 Test loss=2.5365\n",
      "Epoch 80: Train loss=2.5119 Test loss=2.5122\n",
      "Epoch 100: Train loss=2.4919 Test loss=2.4928\n",
      "Epoch 120: Train loss=2.4754 Test loss=2.4767\n",
      "Epoch 140: Train loss=2.4616 Test loss=2.4632\n",
      "Epoch 160: Train loss=2.4499 Test loss=2.4517\n",
      "Epoch 180: Train loss=2.4399 Test loss=2.4419\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    logits = model(X_train)\n",
    "    loss = criterion(logits, Y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_logits = model(X_test)\n",
    "            test_loss = criterion(test_logits, Y_test)\n",
    "        print(f\"Epoch {epoch}: Train loss={loss.item():.4f} Test loss={test_loss.item():.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7743e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kirya\n",
      "zanlei\n",
      "aison\n",
      "vadilins\n",
      "lon\n",
      "uos\n",
      "exsaidanon\n",
      "hhire\n",
      "tana\n",
      "ara\n"
     ]
    }
   ],
   "source": [
    "# inference\n",
    "for _ in range(10):\n",
    "    start_context =[0] * 3 \n",
    "    generated_seq = model.generate(start_context, itos, max_length=20)\n",
    "    print(generated_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76794bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save only the parameters (state_dict) to a file\n",
    "torch.save(model.state_dict(), 'bengio_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa127cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'andan'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create model instance with same architecture\n",
    "model_loaded = BengioLanguageModel(vocab_size=len(stoi), emb_dim=20, context_size=3, hidden_size=100)\n",
    "\n",
    "# Load the saved parameters into model\n",
    "model_loaded.load_state_dict(torch.load('bengio_model.pth', map_location=device))\n",
    "\n",
    "# Set to evaluation mode (important for inference)\n",
    "model_loaded.eval()\n",
    "\n",
    "# Move to device (cuda or cpu)\n",
    "model_loaded.to(device)\n",
    "\n",
    "model_loaded.generate([stoi['e'], stoi['m'], stoi['m']], itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f0da2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
